{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TUZW4Pr4BoW"
   },
   "source": [
    "#  Pre-Modeling : Feature Exploration and Data Preprocessing in Python\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* 1. **Introduction**\n",
    "* 2. **Descriptive Analysis**\n",
    "* 3. **Exploratory Data Analysis (EDA)**\n",
    "    * Univariate Plots\n",
    "    * Multivariate Plots\n",
    "* 4. **Feature Engineering**\n",
    "    * Plotting New Features\n",
    "    * Transform the rest of categorical features to encode the datasets into a numerical one.\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "In this project we walk through the process of examining and understanding the characteristics or attributes (features) of a dataset. The datasets used in this project is \"KaggleV2-May-2016.csv\", which contains informations about medical appointments in Brazil. The main question we are trying to answer here is what factors are important for us to know in order to predict if a patient will show up for their scheduled appointment?\n",
    "\n",
    "\n",
    "#### IMPORTING RELEVANT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-7ZZS5VDX91t"
   },
   "outputs": [],
   "source": [
    "# MAKE KAGGLE API IS INSTALLED. WE'LL DOWNLOAD DATASETS FROM KAGGLE ACCOUNT.\n",
    "#! pip install kaggle\n",
    "\n",
    "# IMPORTING DEPENDENCIES\n",
    "\n",
    "# Ignore warning messages\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Magic command to enable interactive plots in\n",
    "# the notebook interface\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Importing libraries for data analysis\n",
    "import numpy as np, pandas as pd, webbrowser, os, pickle, zipfile\n",
    "\n",
    "\n",
    "# Set up parameters in pandas\n",
    "pd.set_option('display.notebook_repr_html', True, 'display.max_rows', 1000, 'display.max_columns', 100,\n",
    "              'display.float_format', lambda x:\"{:.2f}\".format(x))\n",
    "\n",
    "# Seaborn and Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "# Import feature_extraction from scikit learn\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "# Set up parameters in Matplotlib\n",
    "params = {'axes.titlesize':10.2, 'axes.spines.top':False, 'axes.spines.right':False,\n",
    "          'xtick.labelsize':8.2, 'ytick.labelsize':8.2, 'figure.figsize':[9.8, 8], 'font.size':8}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P6WY6jWSWCvn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: ./kaggle.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Set Up Kaggle API Credentials. This will download a file called kaggle.json.\n",
    "# Ensure that the kaggle.json file is correctly placed in the .kaggle directory \n",
    "# and that it has the correct permissions (chmod 600 ~/.kaggle/kaggle.json)\n",
    "\n",
    "! mkdir -p ~/.kaggle && cp ./kaggle.json ~/.kaggle && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J75NZ9UaF7l6",
    "outputId": "3d7497f8-478e-498a-f049-6950c64d7808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/joniarroba/noshowappointments\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "Downloading noshowappointments.zip to /Users/dambaro/Documents/Exploratory-Analysis\n",
      " 83%|███████████████████████████████▋      | 2.00M/2.40M [00:32<00:06, 64.5kB/s]"
     ]
    }
   ],
   "source": [
    "# Download datasets as a .zip file into current directory. You can use -p flag to \n",
    "# specify a directory where you want datasets to downloaded\n",
    "! kaggle datasets download -d 'joniarroba/noshowappointments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x29yvsHAGf6I",
    "outputId": "1abd3a09-94a3-4c15-ce94-024b7ac3728a"
   },
   "outputs": [],
   "source": [
    "# Unzip the file to access to datasets\n",
    "with zipfile.ZipFile('noshowappointments.zip', 'r')  as z:\n",
    "  z.extractall()\n",
    "\n",
    "# You can remove zip file afterwards\n",
    "! rm -rf noshowappointments.zip && ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a4PRLq-4BoY"
   },
   "source": [
    "#### A. Loading Datasets In Pandas' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "1apNZ9PmiAEP",
    "outputId": "10b36337-fe72-43f0-a33e-985c4b1803da"
   },
   "outputs": [],
   "source": [
    "# Load the dataset into memory using Pandas' DataFrame\n",
    "data = pd.read_csv('KaggleV2-May-2016.csv', parse_dates=['ScheduledDay', 'AppointmentDay'])\n",
    "\n",
    "# Display the first 5 rows of the datasets for sanitation check\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beOzC3PW4Boa"
   },
   "source": [
    "#### B. Displaying datasets in HTML format:\n",
    "\n",
    "This enables us to visualize the data more effectively than in a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "FkPgAMfb4Boa",
    "outputId": "0b36731b-ee6c-45cd-8959-1709bbf2f249"
   },
   "outputs": [],
   "source": [
    "def html_data(data=data[:500]):\n",
    "    # Define a temporary html file\n",
    "    html = data.to_html()\n",
    "\n",
    "    # Save the file\n",
    "    with open('data.html', 'w') as f:\n",
    "        f.write(html)\n",
    "\n",
    "    # Define the full path for file\n",
    "    file_name = os.path.abspath('data.html')\n",
    "\n",
    "    # Open webbrowser\n",
    "    webbrowser.open('file://{}'.format(file_name))\n",
    "\n",
    "# Display data on browser\n",
    "html_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFZIkGInqHGA"
   },
   "source": [
    "## 2. Descriptive Analysis:\n",
    "\n",
    "Descriptive analysis involves describing and summarizing the main features of a dataset. It includes measures such as mean, median, mode, standard deviation, and other summary statistics to provide a clear understanding of the data's characteristics. To do that, we'll use some methods such as info and decribe functions provided by pandas library.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2.1 Info :\n",
    "The \"info()\" returns a summary of the dataset's characteristics, including its shape, which consists of the number of rows and columns. Additionally, it provides information about the column names, their respective data types, and any missing values within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEHuhoWQiF7m",
    "outputId": "6002d27c-1cca-4b66-c8f3-aa33b2747f9f"
   },
   "outputs": [],
   "source": [
    "# Define the info method\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmejCdZmoBes"
   },
   "source": [
    "The dataset comprises 110,527 rows and 14 columns. After conducting a comprehensive examination of the dataset to identify any missing values, we are pleased to report that there were no missing values present in any of the variables. Consequently, there was no need to perform imputation or removal of missing values during the preprocessing stage. The columns appear to have their appropriate data types, with the exception of the datetime variables, which were processed upon loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYLF6R43rMZR"
   },
   "source": [
    "### 2.2 Satistical summary :\n",
    "\n",
    "The \"describe()\" is a useful function for generating descriptive statistics of a DataFrame or Series to helping us quickly understand its distribution and key properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "UP5FVu24i67M",
    "outputId": "efc54904-c5fd-4c5f-8358-eabb1211b677"
   },
   "outputs": [],
   "source": [
    "# Here we use T (transpose) to switch rows and columns\n",
    "# For numerical features\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "GyaeZAjOlV3G",
    "outputId": "fed0bf51-4bb8-42d7-93cb-32f51ba0686f"
   },
   "outputs": [],
   "source": [
    "# Non-numerical features\n",
    "data.describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8JRUemix1w4"
   },
   "source": [
    "\n",
    "#### Key Takeaways :\n",
    "##### Numerical Features :\n",
    "* **Count**, **min**, and **max** are self-explanatory.\n",
    "* **Mean** represents the average value of the data.\n",
    "* **Std**, short for standard deviation, measures the spread or variability of data points from the mean.\n",
    "* **25%**, **50%**, and **75%**, also known as percentiles or quartiles, indicate the values below which a given percentage of observations in a dataset falls. For example, the **25th** percentile of **Age** is **18**, which means that **25%** of the patients are below the Age of **18**.\n",
    "##### Non-Numerical Features :\n",
    "* The \"**unique**\" method indicates the number of distinct values for a given variable.\n",
    "    Top and freq return the class names with the highest value and their frequencies, respectively.\n",
    "\n",
    "Now, let's consider potential anomalies based on domain knowledge :\n",
    "\n",
    "* **Age** appears to have no significant outliers, but there are some negative values, which are abnormal. Consider converting them into positive values.\n",
    "* **Handicap** has more than two categories. Upon investigation, we discovered that these represent the number of disabilities a patient might have. You may need to convert them into a binary class.\n",
    "\n",
    "* **ScheduledDay** and **AppointmentDay** columns are not included in the describe method due to their datetime series format. These features will be analyzed separately in the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUuSXjFq3WOD"
   },
   "source": [
    "## 3. Exploratory Data Analysis (EDA):\n",
    "\n",
    "EDA is the process of visually and statistically exploring data to uncover patterns, trends, and relationships between variables. It involves creating various plots and charts to gain insights into the data and identify potential areas for further investigation.\n",
    "\n",
    "We can divide the exploratory data analysis into two parts: Univariate and Bivariate Plots.\n",
    "\n",
    "\n",
    "### 3.1 Univariate plots :\n",
    "\n",
    "Univariate plots are graphical representations used in feature exploration to visualize the distribution and frequency of values within a single variable. These plots are helpful in identifying outliers, understanding central tendency, assessing variability, and examining the shape of the distribution. They also assist in identifying patterns, trends, or anomalies that might require further investigation or influence data analysis decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfEpbs1hMj0I"
   },
   "source": [
    "#### a. Columns Partition :\n",
    "\n",
    "Partitioning columns into distinct groups based on their data types to facilitate the creation of appropriate plots for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ft4uQfw-i9cR",
    "outputId": "a28ac7c9-5b97-422d-d60f-41569682226e"
   },
   "outputs": [],
   "source": [
    "# Define a copy of the datasets called df in order to preserve the original\n",
    "df = data.copy()\n",
    "\n",
    "# Check the number of distinct values for each variables\n",
    "for column in df.columns:\n",
    "    print('{:25} {}'.format(column, len(df[column].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdBSCM624Bof"
   },
   "source": [
    "#### b. Define a function for partioning the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7WEL6QN4Bof",
    "outputId": "d4913fe5-b2c4-4609-d496-626a238cf140"
   },
   "outputs": [],
   "source": [
    "# Creating a function to group columns into different data types\n",
    "def partitionningThefeatures(df=df):\n",
    "    \"\"\"\n",
    "    This function generates lists of columns based on their data types\n",
    "    for a giving datasets.\n",
    "    \"\"\"\n",
    "    # Define empty lists for column partitioning\n",
    "    date_cols, cont_cols, cat_cols = [], [], []\n",
    "\n",
    "    # Iterate through columns to select proper data types\n",
    "    for column in df.columns:\n",
    "        # Check data types\n",
    "        if df[column].dtype == 'datetime64[ns, UTC]':\n",
    "            # Append to date_vars list if it's a datetime column\n",
    "            date_cols.append(column)\n",
    "\n",
    "        # Choose an arbitrary number for selecting categorical variables\n",
    "        elif len(df[column].value_counts()) < 90:\n",
    "            # Append to cat_vars list if it has fewer than 90 unique values\n",
    "            cat_cols.append(column)\n",
    "\n",
    "        else:\n",
    "            # Append to cont_vars list if it doesn't meet the above conditions\n",
    "            cont_cols.append(column)\n",
    "\n",
    "    # Return the generated lists\n",
    "    return cont_cols, cat_cols, date_cols\n",
    "\n",
    "cont_cols, cat_cols, date_cols = partitionningThefeatures(df)\n",
    "\n",
    "# Print the partitioned variables\n",
    "print('Date time variables :\\t{}\\n\\nContinuous variables :\\\n",
    "\\t{}\\n\\nCategorical variables :\\t{}'.format(date_cols, cont_cols, cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ipd8cRhn4Bog"
   },
   "source": [
    "#### c. Define A Univariate Plots Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "R5AvR3kp4Bog",
    "outputId": "2bc6e819-1032-4898-a360-2fde750143f7"
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# Create an univariate plot founction\n",
    "def featuresPlotting(cont_cols, cat_cols):\n",
    "    \"\"\"This function outputs individual plot for a\n",
    "    given set of features\"\"\"\n",
    "    # Define a figure for plotting\n",
    "    plt.figure(figsize=[10, 14])\n",
    "\n",
    "    # Define a count plot\n",
    "    countplot = 1\n",
    "\n",
    "    # Define the number of columns\n",
    "    total_vars = len(cont_cols) + len(cat_cols)\n",
    "\n",
    "    # Define the number of rows\n",
    "    num_rows = int(np.ceil(total_vars / 2))\n",
    "\n",
    "    # Define the minimuim value of columns\n",
    "    num_cols = min(total_vars, 2)\n",
    "\n",
    "    # Iterate through continous columns\n",
    "    for column in cont_cols:\n",
    "        # Define subplots\n",
    "        plt.subplot(num_rows, num_cols, countplot)\n",
    "\n",
    "        # Plot each continuous variable\n",
    "        df[column].plot(kind='hist', # plot type\n",
    "                        bins=100,    # Set bins\n",
    "                        title=column, # Chart name\n",
    "                        color='lightslategrey', # Set color\n",
    "                        alpha=.7 # adjust the transparency\n",
    "                       )\n",
    "\n",
    "        # Adjust figure axes\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Increment the plot count\n",
    "        countplot+=1\n",
    "\n",
    "    # Iterate through categorical columns\n",
    "    for column in cat_cols:\n",
    "        # Create suplots or categorical variables\n",
    "        plt.subplot(num_rows, num_cols, countplot)\n",
    "\n",
    "        # Plot each categorical variable\n",
    "        df[column].value_counts().sort_index().plot(kind='bar', # Figure type\n",
    "                                                    width=.8, # Set the bar width\n",
    "                                                    title=column, # Chart names\n",
    "                                                    color='lightslategrey', # Set color\n",
    "                                                    alpha=.7, # adjust the transparency\n",
    "                                                    sharey=True)\n",
    "\n",
    "        if column == 'Neighbourhood':\n",
    "            plt.xticks([])\n",
    "        plt.xlabel(None)\n",
    "\n",
    "        # Adjust figure axes\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Set a title for figure\n",
    "        plt.suptitle(\"Features' Freqeuncy Distributions\\n\\n\", fontsize=14, fontweight='bold', style='oblique', alpha=.7)\n",
    "\n",
    "        # Set y-axis label\n",
    "        plt.ylabel('Count')\n",
    "\n",
    "        # Increment the plot count\n",
    "        countplot+=1\n",
    "\n",
    "# Plot feature distributions\n",
    "featuresPlotting(cont_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpzQKLpT_7ec"
   },
   "source": [
    "In the preceding plots, **PatientiD** and **AppointmentID** don't seem meaningful for our predictive modeling. Let's perform some further analysis before we can remove them.\n",
    "\n",
    "As mentioned earlier we can see some negative values on the **Age** chart. We'll need to fix them later on. There are also a few hikes seen with infant patients holding the record.\n",
    "\n",
    "**Handcap** feature has more than 2 class categories and after speaking with the personal we found out that these values are numbers of handicaps a patient might have. We will also need to process that as well.\n",
    "\n",
    "The target variable seems to have about 80% of patients showed up at their appointments and only 20% otherwise which clearly indicates that we're dealing with an **imbalance class classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlmC_sWP4Boh"
   },
   "source": [
    "##### d. Compute PatientiD And AppointmentID Duplicates And Value Counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4YKIkyF4Boh",
    "outputId": "87bf3f14-45e7-4691-be51-daab1054fe64"
   },
   "outputs": [],
   "source": [
    "# Loop through continuous columns\n",
    "for column in cont_cols:\n",
    "    # Print their duplicates and shapes\n",
    "    print(f'{column}:\\n{\"Distinct Values\":20} {len(df[column].value_counts())}\\\n",
    "    \\n{\"Shape\":20} {df[column].shape[0]}\\n{\"Duplicates\":20} {df[column].duplicated().sum()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVYeG9y6EB3G"
   },
   "source": [
    "* **AppointmentID** has a mixed decimal and integer format, which can be fixed during the processing stage. However, it doesn't appear to be a useful feature, except for it lacks any duplicates that could be used as index.\n",
    "* However, **PatientiD** contains about 49,000 duplicate entries, indicating that on average, every patient has about two appointments.\n",
    "\n",
    "Since these columns don't seem to contribute significantly to our predictive modeling, it's reasonable to remove them from the datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXHrEYhN4Boi"
   },
   "source": [
    "##### e. Remove AppointmentID and PatientId Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpO8wq9kB1ZR",
    "outputId": "3692d188-23f5-4fd0-cf67-c82e84fe5f45"
   },
   "outputs": [],
   "source": [
    "# Remove AppointmentID, PatientId\n",
    "df.drop(['AppointmentID', 'PatientId'], axis=1, inplace=True)\n",
    "\n",
    "# Store the remaining features in new variables\n",
    "cont_vars, cat_vars, date_vars = partitionningThefeatures(df)\n",
    "\n",
    "# Let's display the news variables\n",
    "print(cont_vars)\n",
    "print(cat_vars)\n",
    "print(date_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XUCF-92CrId"
   },
   "source": [
    "### 3.2 Multivariate plots :\n",
    "\n",
    "Multivariate plots (comparative analysis of multiple variables, if we compare the correlation of two variables, it is called bivariate analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "VK2fSRStNTXg",
    "outputId": "a05ed4f9-7cce-441f-ec08-cc932ff90b98"
   },
   "outputs": [],
   "source": [
    "# Store the output in a variable for further analysis\n",
    "target = cat_vars.pop(cat_vars.index('No-show'))\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeWfNfCC4Boj"
   },
   "source": [
    "#### a. Define a function for bivariate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uFpWzEcB4Boj",
    "outputId": "4d8eadfd-020d-46ae-e67a-0e9515056e22"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define a Bivariate plotting function\n",
    "\n",
    "def feature_vs_target_plot(cont_vars, cat_vars, target):\n",
    "    \"\"\"\n",
    "    This function generates the interaction between each\n",
    "     feature and the target variable.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define total number of columns\n",
    "    tota_cols = len(cont_vars) + len(cat_vars)\n",
    "\n",
    "    # Define the number of rows\n",
    "    num_rows = int(np.ceil(tota_cols / 2))\n",
    "\n",
    "    # Mininuim value of columns\n",
    "    num_cols = min(tota_cols, 2)\n",
    "\n",
    "    # Define a figure for the plots\n",
    "    plt.figure(figsize=[10, 14])\n",
    "\n",
    "\n",
    "    # Initialize the plot count\n",
    "    plot_count = 1\n",
    "\n",
    "    # Iterate through continuous variables\n",
    "    for column in cont_vars:\n",
    "        # Set a grid for the number of plots\n",
    "        plt.subplot(num_rows, num_cols, plot_count)\n",
    "\n",
    "        # Iterate through the target variable's classes\n",
    "        for status in df[target].unique():\n",
    "            # Filter the datasets based on the target variable value\n",
    "            df.loc[df[target] == status, column].plot(kind='hist', bins=len(df[column].unique()),\n",
    "                                                     label=status, density=True, alpha=.4)\n",
    "\n",
    "            # Set the x-axis label as the column name\n",
    "            plt.xlabel(column, fontsize=10.2)\n",
    "\n",
    "            # Add a legend\n",
    "            plt.legend()\n",
    "\n",
    "            # Set the super title for the figure\n",
    "            plt.suptitle('Relationships Between Features And Target Variable\\n\\n',\n",
    "                         fontweight='bold', fontsize=15, alpha=.6, style='oblique')\n",
    "\n",
    "            # define better names for the target classes for a better plot\n",
    "            plt.legend(['attended', 'missed'])\n",
    "\n",
    "            # Increment the plot count\n",
    "            plot_count += 1\n",
    "\n",
    "            # Adjust the layout\n",
    "            plt.tight_layout()\n",
    "\n",
    "    # Iterate through categorical variables\n",
    "    for column in cat_vars:\n",
    "        # Create a subplot\n",
    "        ax = plt.subplot(num_rows, num_cols, plot_count-1)\n",
    "\n",
    "        # Compute the cross-tabulation between the column and target variable\n",
    "        crosstabb = pd.crosstab(df[column], df[target])\n",
    "        # Switxh up cross-tabulation columns\n",
    "        crosstabb = crosstabb.iloc[:, ::-1]\n",
    "\n",
    "        # Plot the cross-tabulation as a stacked bar chart\n",
    "        crosstabb.plot(kind='bar', width=.8, alpha=.5, stacked=True,\n",
    "                       sharey=True, ax=ax)\n",
    "        if column == 'Neighbourhood':\n",
    "            plt.xticks([])\n",
    "\n",
    "        # define better for the target classes for a better plot\n",
    "        plt.legend(['missed', 'attended'])\n",
    "\n",
    "        # Set the x-axis label as the column name\n",
    "        ax.set_xlabel(column, fontsize=10.2)\n",
    "\n",
    "        # Set y-axis label\n",
    "        plt.ylabel('frequency')\n",
    "\n",
    "        # Adjust the subplot position\n",
    "        plt.subplots_adjust(bottom=.04)\n",
    "\n",
    "        # Increment the plot count\n",
    "        plot_count += 1\n",
    "\n",
    "# Call the function with the appropriate parameters\n",
    "feature_vs_target_plot(cont_vars, cat_vars, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSaTGEfQqlKl"
   },
   "source": [
    "Across all the categorical features, it appears that there is minimal to no discernible impact on patients' decisions regarding whether they showed up at their appointments. However, it is worth noting that the 'SMS_receive' feature has a marginal impact, despite the fact that only 32% of patients in the dataset had received text messages.\n",
    "\n",
    "Both the **'Age'** and **'Gender'** variables do not seem to have a direct effect on the target variable, as previously discussed. Nevertheless, given their significance to our client, we will generate multivariate plots that combine these features with the target variable to investigate whether a third feature could potentially act as an interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxJUPjDotPzM"
   },
   "source": [
    "#### b. Age against Status On Gender :\n",
    "\n",
    "Let's create a multivariable plot between Age, Gender and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "9n9Agy004Bok",
    "outputId": "6e3b42e6-7c8f-4e9d-9593-c50ef9504dea"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define a figure for the plot\n",
    "plt.figure(figsize=[10, 4.8])\n",
    "\n",
    "\n",
    "# Initialize plot count\n",
    "plot_count = 1\n",
    "\n",
    "# Iterate through target classes\n",
    "for status in df[target].unique():\n",
    "    # Create subplots for each target class\n",
    "    plt.subplot(1, 2, plot_count)\n",
    "\n",
    "    # Filter DataFrame based on target class\n",
    "    df_sta = df.loc[df[target] == status]\n",
    "\n",
    "    # Iterate through Gender classes within each target class\n",
    "    for gender in df_sta['Gender'].unique():\n",
    "        # Filter DataFrame based on Gender class\n",
    "        gend_data = df_sta.loc[df_sta['Gender'] == gender, 'Age'].value_counts().sort_index()\n",
    "\n",
    "        # Plot the values of the Age distribution\n",
    "        gend_data.plot(label=gender, grid=False)\n",
    "\n",
    "        # Set plot title and axis labels\n",
    "        plt.xlabel('Age', fontsize=11.4)\n",
    "        plt.ylabel('Frequency', fontsize=10.4)\n",
    "\n",
    "        # Set the axis limits based on the maximum Age value and the maximum frequency in the current Gender class\n",
    "        plt.axis([0, df_sta.Age.max(), 0, gend_data.max()])\n",
    "\n",
    "        # Adjust axes positionss\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if status == 'No':\n",
    "\n",
    "            plt.title(f'\\n\\nAge Freq Wise of Patients\\n {\"Attended\"} For Both Genders', fontsize=10,\n",
    "                      fontweight='bold', alpha=.5, style='oblique')\n",
    "\n",
    "        else:\n",
    "\n",
    "            plt.title(f'\\n\\nAge Freq Wise of Patients\\n {\"Missed\"} For Both Genders', fontsize=10,\n",
    "                      fontweight='bold', alpha=.5, style='oblique')\n",
    "\n",
    "\n",
    "        # Add legend to differentiate Gender classes\n",
    "        plt.legend()\n",
    "\n",
    "    # Increment plot count\n",
    "    plot_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vWvmM_c4Bol"
   },
   "source": [
    "On female chart children and women in their 40s and 50s are more likely to show up for their appointments. This pattern makes sense, as parents tend to prioritize their children's health, and older patients are more susceptible to diseases.\n",
    "\n",
    "\n",
    "In contrast, while the pattern appears to be similar in both charts for male patients it's worth noting that enfants through adolescent patients are more likely to show up for their appointments.\n",
    "\n",
    "These observations suggest that the factors influencing appointment attendance may vary between genders and age groups. Thus we'll include both **'Age'** and **'Gender'** in our predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbIUtAp5bDgN"
   },
   "source": [
    "### 3.3 Analyzing Datetime Series Variables:\n",
    "\n",
    "#### a Feature Engineering :\n",
    "\n",
    "As a general practice, we typically avoid performing feature engineering during the initial feature exploration. However, in this particular case, we will need to extract some components from the datetime features as new columns to facilitate further analysis.\n",
    "\n",
    "* Define a new variable called '**WaitingTime**', which represents the time difference between the '**ScheduledDay**' and '**AppointmentDay**', to investigate its potential impact on the target variable.\n",
    "\n",
    "* Define new variables for the '**month**', '**week**', and '**day**' components from both datetime series. We will need to adjust some of their values to ensure they make sense, especially if '**ScheduledDay**' is a date ahead of  '**AppointmentDay**'.\n",
    "\n",
    "It's worth noting that, since the '**AppointmentDay**' hours, minutes, and seconds components aare zeros, we decided not to include these components present in '**ScheduledDay**' variable. Similarly, the '**Year**' component can be omitted, as the dataset only contains samples from the year 2016, making it challenging to compare it with another year for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oghOjy84Bol"
   },
   "source": [
    "#### b. Define a fuction that generates datetime series components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "5rGl8cZW4Bol",
    "outputId": "2f3549f1-519a-4cf5-cce9-8e2ae42c53c1"
   },
   "outputs": [],
   "source": [
    "# Create a function that generates new components\n",
    "def datetime_components(df, date_vars):\n",
    "    \"\"\"\n",
    "    This function generates new features based on datetime variables.\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame.\n",
    "        date_vars (list): List of datetime variables to process.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The modified DataFrame with new features.\n",
    "    \"\"\"\n",
    "    # Define WaitingTime feature as the difference in days between the two dateime Series\n",
    "    df['WaitingTime'] = (df['AppointmentDay'] - df['ScheduledDay']).dt.days\n",
    "\n",
    "    # Loop through indices as rows\n",
    "    for index, row in df.iterrows():\n",
    "        # Check for 'Waitime' instances values less than zero\n",
    "        if row['WaitingTime'] < 0:\n",
    "            # Switch vales between two datetimes series\n",
    "            df.at[index, 'ScheduledDay'], df.at[index, 'AppointmentDay'] = \\\n",
    "            df.at[index, 'AppointmentDay'], df.at[index, 'ScheduledDay']\n",
    "\n",
    "    # Loop through datetime features\n",
    "    for column in date_vars:\n",
    "        # Loop through indices and datetime components\n",
    "        for i, components in enumerate(['Mon', 'Week', 'Day']):\n",
    "            # Define month, weekday, and day variables for both datetime Series\n",
    "            df[f'{column}_{components}'] = [df[column].dt.month, \\\n",
    "                                                df[column].dt.weekday, df[column].dt.day][i]\n",
    "\n",
    "    # Convert 'WaitingTime' into positive values\n",
    "    df.WaitingTime = np.abs(df.WaitingTime)\n",
    "\n",
    "    # Drop the original datetimes series\n",
    "    df.drop(date_vars, axis=1, inplace=True)\n",
    "\n",
    "    # Return the modified DataFrame\n",
    "    return df\n",
    "\n",
    "# Define new df with new input variables\n",
    "df = datetime_components(df, date_vars)\n",
    "\n",
    "# Display first five rows\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2a0OLEL4Bol"
   },
   "source": [
    "#### c. Univariate plot of New Features :\n",
    "\n",
    "Let's plot the new features individually to learn about their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vvbBqHoiudq-",
    "outputId": "a921a3de-dd5e-4736-938b-116b9ab4d76b"
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# Define lists for new variables only\n",
    "new_contVars = [df.columns.tolist().pop(df.columns.tolist().index('WaitingTime'))]\n",
    "new_catVars = df.columns.tolist()[df.columns.tolist().index('ScheduledDay_Mon'):]\n",
    "\n",
    "# Having created Univariate function early on we can just apply that on the lists of\n",
    "# new the variables to plot their frequency distributions.\n",
    "featuresPlotting(new_contVars, new_catVars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEXZ4P_2Tn4I"
   },
   "source": [
    "* **Waitingtime** peek of the distribution is at 0 which suggests a large number of patients had same-day appointments or in very short period of waiting times. As you move to the right on the distribution, the number of patients decreases, indicating longer waiting times with right tail containing a few patients who had to wait over 100 days for their appointments\n",
    "\n",
    "\n",
    "* **Month** plots in both datetime series don't seem to containing all the 12 months of the year. Clearly this datasets is fairly unsufficient by machine learning standards, but perfect to get started.\n",
    "While month of May has the highest registered patients for appoimntment, the distribution of patients on scheduled day throughout the months seems normal on the other hand.\n",
    "\n",
    "* **Week** plots containing six bars indicating the clinic closing on Sundays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ogun0t34Bom"
   },
   "source": [
    "#### d. Bivariate Plots of New features againts target :\n",
    "\n",
    "Let's plot to each new feature against the target to learn about their relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Az3668CRvAve",
    "outputId": "6bafca32-0b54-4139-b87f-fd90745b86a2"
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "# Again we can achieve this plot by using the bivariate function we created earlier.\n",
    "feature_vs_target_plot(new_contVars, new_catVars, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hsgr8_534Bon"
   },
   "source": [
    "New features appear to exhibit variations across different values of the target variable. Therefore, we will incorporate them into our predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Encode Remaining Categorical Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZS5gTYP-lz-L"
   },
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "df['No-show'] = np.where(df['No-show'] == 'No', 1, 0)\n",
    "\n",
    "# Binarize Gender variable\n",
    "df['Gender'] = np.where(df.Gender == 'F', 0, 1)\n",
    "\n",
    "# Encode Neighbourhood feature\n",
    "# Set number of feature for hashing\n",
    "n_features = 40\n",
    "# Define a dictionary key value pair where value is the neighbourhood\n",
    "neigh_dict = [{'Neighbourhood':val} for val in df['Neighbourhood']]\n",
    "\n",
    "# Intaantiate the FeatureHasher class\n",
    "hasher = feature_extraction.FeatureHasher(n_features=n_features, input_type='dict')\n",
    "# Fit and Transform the Neighbourhood Feature and convert into array\n",
    "hasher_array = hasher.fit_transform(neigh_dict).toarray()\n",
    "# Define column names for matrix\n",
    "col_names = ['neigh_' + str(i) for i in range(n_features)]\n",
    "# Define a dataframe using the hashing array created\n",
    "sparse_df = pd.DataFrame(hasher_array, columns=col_names).astype(int)\n",
    "\n",
    "# Concatenate the sparse data with original and delete Neighbourhood\n",
    "# feature from datasets\n",
    "df = pd.concat([df.drop('Neighbourhood', axis=1), sparse_df], axis=1)\n",
    "\n",
    "# Display the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we provided insights into the dataset's structure, distributions of features, and their relationships with the target variable, and some feature engineering date time series features in order to continuing exploring the data, laying the groundwork for further analysis...\n",
    "\n",
    "\n",
    "**Next in our modeling project, with informations gain unpon exploring the data, we'll perform some preprocessing including some feature engineering as well for our predictive modeling.**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
